{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgk9q18I79wIq1Y9uaVKe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminnigjeh/automated_data_mining/blob/main/similarity_search_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdpIHDgVwsrz"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MinHash:\n",
        "    def __init__(self, num_hashes=100):\n",
        "        self.num_hashes = num_hashes\n",
        "        self.seeds = [random.randint(0, 2**32 - 1) for _ in range(num_hashes)]\n",
        "\n",
        "    def _hash(self, x, seed):\n",
        "        return int(hashlib.md5((str(seed) + x).encode('utf8')).hexdigest(), 16)\n",
        "\n",
        "    def compute(self, set_data):\n",
        "        min_hashes = [min(self._hash(el, seed) for el in set_data) for seed in self.seeds]\n",
        "        return min_hashes\n",
        "\n",
        "    def jaccard_similarity(self, set1, set2):\n",
        "        min_hash1 = self.compute(set1)\n",
        "        min_hash2 = self.compute(set2)\n",
        "        return sum(1 for a, b in zip(min_hash1, min_hash2) if a == b) / self.num_hashes\n",
        "\n",
        "\n",
        "def hashing(str1, str2):\n",
        "    random.seed(100)\n",
        "    n = 3\n",
        "    set1 = {str1[i:i+n] for i in range(len(str1) - n + 1)}\n",
        "    set2 = {str2[i:i+n] for i in range(len(str2) - n + 1)}\n",
        "    minhash = MinHash(num_hashes=100)\n",
        "    similarity = minhash.jaccard_similarity(set1, set2)\n",
        "    return(1 - similarity)"
      ],
      "metadata": {
        "id": "UG2N_r-xzkg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_result = pd.read_csv('E:/myresult.csv')\n",
        "\n",
        "cast = my_result['cast']\n",
        "\n",
        "cast_f = []\n",
        "import ast\n",
        "\n",
        "for i in range(0, len(cast)):\n",
        "    cast_f.append(ast.literal_eval(cast[i]))\n",
        "\n",
        "hash = []\n",
        "a = len(my_result['sequence'])\n",
        "for i in range(0, a):\n",
        "    hash.append(hashing(my_result['sequence'][i], my_result['sequence'][1700]))\n",
        "    print(hash[i])"
      ],
      "metadata": {
        "id": "BmTy0ndy1hN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Generate synthetic data\n",
        "X = np.array(cast_f)  # 1600-dimensional input\n",
        "y = np.array(hash)     # Target variable between 0 and 1\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create a neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(1600,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Loss (MSE): {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "IRtPqC_qz5_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to plot distribution\n",
        "def plot_distribution(data):\n",
        "    # Check if the data is a list or a NumPy array\n",
        "    if isinstance(data, list):\n",
        "        data = np.array(data)\n",
        "\n",
        "    # Set up the figure and axes\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot histogram\n",
        "    sns.histplot(data, bins=30, kde=True, color='blue', alpha=0.6, stat='density')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title('Distribution of Numbers')\n",
        "\n",
        "    # Show grid\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "sdKhITDG0jDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Example true labels and predicted labels\n",
        "y_true = [0 if x < 0.5 else 1 for x in y_test]\n",
        "y_pred = [0 if x < 0.5 else 1 for x in a]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Create a confusion matrix display\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_true))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydHNxN8J2IsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = 'SQAEFEKAAEEVRHLKTKPSDEEMLFIYGHYKQATVGDINTERPGMLDFTGKAKWDAWNELKGTSKEDAMKAYINKVEELKKKYGI'\n",
        "\n",
        "index = 1\n",
        "\n",
        "insert_string = '[1458]'\n",
        "\n",
        "new_string = \"\".join([sequence[:index], insert_string, sequence[index:]])\n",
        "\n",
        "print(new_string)"
      ],
      "metadata": {
        "id": "5k48s5UW2KBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}